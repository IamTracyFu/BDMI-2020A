# 课程小结 LESSON 8

## 一、pandas

1. loc是行名/列名；iloc是数字编号

## 二、多层神经网络

1. softmax处理：计算一个概率分布的向量
2. 分对数 Logit模型：
   - 与sigmod函数互为反函数
3. 神经网络层数：
   - 如何确定权重？先随即生成权重；再进性优化（自动化确定权重）
   - 自动化确定的流程：也即神经网络的训练
     - 确定一个损失函数
     - 权重初始化
     - 反向传播（BP）
     - 权重修正
   - 训练：用带标签的训练样本对神经网络进行学习
     - 度量函数：也成为损失函数（LOSS）或称为成本函数（COST）
       - 对于回归任务，通过均方误差（MSE）
       - 对于分类任务，通过交叉熵（CE）
   - 梯度下降法：
     - 用损失函数计算每个权重的偏导，即可以求出梯度
   - 权重更新：随机梯度下降法：随机的是选出来进行训练的样本，梯度计算的方法是确定的。
   - 分批训练（Batch training）
     - 小批量训练（mini-batch）：把数据切分成大小相同的几个子集
   - epoch（时代）：一次完整的训练
   - 整个训练集称为一个批次（batch）
4. 用张量（tensor）表示神经网络：
   - 图像：行、列、颜色 就可以用三维张量来表示

