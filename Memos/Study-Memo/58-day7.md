# Day 7
### Numpy/Scipy介绍
NumPy（Numerical Python）是Python的一个扩展程序库，支持大量的维度数组与矩阵运算。
- array()函数创建数组
  - 不限于integers
  - 接受tuples与lists的混合
  - dtype option设置数据类型 e.g.: array(((1,2),(3,4)), dtype=complex)
  - 数组方圆括号皆可
- arange()函数创建顺序数列
- reshape()函数改变矩阵结构
- sin() sqrt()等函数进行算术运算
- ones() zeros()函数分别创建全一、全零矩阵
- dot()函数点乘矩阵
- 无++或--，而使用+=或-=
- ravel()转为一维数组
- transpose()倒置矩阵
- matmul()矩阵相乘
- identity()创建单位矩阵
- vstack()垂直叠加2阵列
- shape()得到矩阵的形状
- dtype()得到数据类型
SciPy与NumPy比较相近
- scipy.linalg.inv取逆
- scipy.linalg.eig特征值
- scipy.spatial.distance距离计算
### 人工神经元
- 单个人工神经元：

  一组输入的线性加权叠加，经过一个非线性变换进行输出
  
  加权可用dot函数
  
- 激活函数：
  
  - sigmoid：逻辑斯提函数(logistic function)或S形函数

$$
sigmoid(x) = \frac{1}{1 + e^{-x}}
$$

  - tanh：双曲正切

$$
tanh(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}
$$

  - ReLU：(rectified linear units)，整流线性单元
    
$$
ReLU(x) = max(x, 0)
$$

- PReLU：(parametric ReLU)，参数化整流线性单元
$$
PReLU(x) = \begin{cases}
λx, & x < 0, (λ为参数) \\
x, & x \geq 0.
\end{cases}
$$
- Softplus：ReLU函数的软化版本
$$
Softplus(x) = ln{(1 + e^{x})}
$$
- 饱和型S函数：即阶跃函数

- logit函数：

  与sigmoid函数互为反函数
$$
logit(x) = ln{\frac{x}{1-x}}
$$
- SoftSign函数：
$$
SoftSign(x) = \frac{x}{1-|x|}
$$
- hard tanh函数：
$$
hardtanh(x) = \begin{cases}
-1, & x\leq-1,\\
x, & |x|<1,\\
1, & x\geq1.
\end{cases}
$$
- softmax函数：
$$
softmax(z_m) = \frac{e^{z_m}}{\Sigma_k{e^{z_k}}}
$$

### 布尔运算

与（AND）、或（OR）、非（NOT）、与非（NAND）、异或（XOR），其中前四种布尔运算可用sigmoid函数模拟。

- 与运算用sigmoid函数模拟，利用其性质sigmoid(-5)~0, sigmoid(5)~1
  
  - X1加权20，X2加权20，-1偏置权30来实现与运算
  
- 或运算用sigmoid函数模拟
  
  - X1加权20，X2加权20，-1偏置权10来实现或运算
  
- 非运算用sigmoid函数模拟
  
  - X加权-20，1偏置权10来实现非运算
  
- 与非运算用sigmoid函数模拟

  - X1加权-20，X2加权-20，1偏置权30来实现与非运算

- 异或运算

  - 进行复合的布尔运算

    X1 XOR X2 = {X1 OR X2} AND {NAND{X1, X2}}

    或

    X1 XOR X2 = {X1 OR X2} AND {(NOT X1) OR (NOT X2)}

    （与非即非或）
### 神经网络

多层神经元形成神经网络，又称为深度学习，主要解决两类任务：

- 分类任务：对新数据进行集合分类

- 预测任务：预测新的数值

- 手动调参

  - 正负相关？ 重要程度？

- 前馈网络(Feedforward NN)
  
  - 多层全连接网络(FCN)、多层感知机(MLP)、多个密集层网络(Dense)
  
- Softmax处理

  计算出一个概率分布向量

- 神经网络的训练
  - 1.确定损失函数（Loss）
  - 2.权重初始化（Initialization）
  - 3.反向传播（Back Propagation）
  - 4.权重修正（Weights Adjusting）

神经网络方法属于机器学习的监督学习方法，训练数据由样本（sample）集组成，每个样本上有标签（label）
