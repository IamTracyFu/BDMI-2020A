## 第八节课：深度学习初步

### 深度学习2：多层神经网络

#### pandas学习

pandas是一个强大的分析结构化数据的工具集，使用基础是numpy。

用于数据挖掘和数据清洗

常用数据结构：一维Series，二维DataFrame

pd.Seires(元素，index)（index即坐标，默认是0，1，2，……）

二维:从series字典中构造

操作csv文件：

从csv文件中读取：pd.read_csv('foo.csv')

保存：df.to_csv('foo.csv')

```python
import numpy as np
import pandas as pd

d = {
    'ID':pd.Series([123456 , 6789123],index=['小明','小强']),
    'gender':pd.Series(['male','male'],index=['小明','小强'])
}

df=pd.DataFrame(d)
print(df)
print(df.columns)
print(df.index)
df.iloc[1]
df.loc['小明']
df = df.T			#转置
print(df)
```

#### 用人工神经元进行二元分类

对课上同学身高体重的数据按性别做一个分类



深度比广度的能力是指数级增长（当然太深也不行，否则会过拟合）



两层网络结构可以解决XOR问题

对所有输出层神经元的输出，认为某一输出越大，越可能是某一结果，则可用Softmax（）将输出都归一化。

自动化的权重确定方法：确定损失函数，初始化权重，反向传播，权重修正

 损失函数：方差（预测/回归问题）和交叉熵（分类问题）

#### 反向传播算法/梯度算法

要去找损失函数最小值，则去求梯度。由链式法则，为求$\frac{\part l}{\part w_n}$，则可以求$\frac{\part h_n}{\part h_{n-1}}$和$\frac{\part h_{n-1}}{\part w_{n-1}}$。

权重更新：随机梯度下降法（随机指样本随机），基于该样本逐层调整权重参数，再选取下个参数。其中，调整的比例系数称为学习率，即求出梯度后，要对参数改变多少倍的梯度。

#### 实际训练过程

实际训练过程中，考虑到样本也会有噪音，会使用小批次训练（即每次投入固定数量的样本集），这样能保证样本的噪音被抑制，同时又保证每次训练时间不是太长。
