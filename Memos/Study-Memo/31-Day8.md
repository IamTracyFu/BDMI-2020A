##  第八周学习小结

1. 导入pandas包进行了数据处理操作

2. 损失函数的度量函数：

   1. 回归问题一般用均方误差公式（MSE）
   2. 分类问题一般用交叉熵公式（CE）

3. 权重更新——随机梯度下降法：

   步骤：

   1. 随机初始化每个神经元输入权重和偏差；
   2. 选取一个随机样本；
   3. 根据网络的输出结果，从最后一层开始后，逐层计算每层权重的偏导数；
   4. 逐层调整每层的权重，产生新的权重值；
   5. 返回到步骤2，继续随机选取下一个样本。

   实际训练时会采用小批量训练方式（mini-batch）

   迭代（iteration）——一次迭代，即更新一次参数

   时代（epoch）——一个时代，指训练集中的所有训练样本都被送入网络完成一次训练的过程

   
tensorflow

​	深度or广度？深度的拟合能力更强，能提取更多特征

-[课堂代码](https://github.com/Brickzhuantou/BDMI_learn/blob/main/practice_in_class/practice8.ipynb)