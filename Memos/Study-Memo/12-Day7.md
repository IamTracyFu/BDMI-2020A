## 第七周课程小结
今天学习了numpy的相关内容，以及深度学习的两个部分：
##### Numpy的安装与学习
学习了矩阵的变化方法，和基本的矩阵运算；
##### 学习人工神经元的基本知识
单个人工神经元：一组输入的线性加权叠加/经过一个非线性变换进行输出；\
激活函数：Simgoid函数，又称为logistic或S函数……\
尝试用numpy画出Simgoid函数、RelU函数；\
用numpy描述一个完整的神经元；
##### 用python表示与门、或门、异或门
通过设置权重和Simgoid函数，实现布尔运算；
##### 神经网络的用途
神经网络属于机器学习的监督学习方法；\
多层的神经网络又称为深度学习，主要用于解决【分类】和【预测】问题；\
*** 用途实例：根据身高体重、头发长度判断性别；\
→→→ 经验调参法进行权重设置
##### 多层神经网络
网络的层数增加后，预测或分类的能力就会提升;\
用numpy实现Softmax函数和logit函数；
##### 损失函数
神经网络方法：监督学习的特点是根据训练数据集进行学习，然后推断新的实例。训练数据集由样本组成，每个样本上都有相应的标签，用来指导训练过程。\
定义损失函数：对于回归任务，通过均方误差计算损失；对于分类任务，通过交叉熵计算损失。
#### [课程代码](https://github.com/HuShiruo/BDMI-course/blob/main/W7_class_code.ipynb)
